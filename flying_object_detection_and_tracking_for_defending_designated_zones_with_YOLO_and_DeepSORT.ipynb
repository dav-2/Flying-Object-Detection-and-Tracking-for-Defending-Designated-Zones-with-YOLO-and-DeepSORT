{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Flying Object Detection and Tracking for Defending Designated Zones with YOLO and DeepSORT**\n",
        "\n",
        "This demo project focuses on developing an AI-powered system designed to detect, track, and classify flying objects in real time, with the primary goal of defending a designated Region of Interest (ROI) from a specific type of object—in this example, birds. By combining deep learning models and tracking algorithms, the system processes video feeds to differentiate between target objects (birds) and non-target objects (such as aircraft).\n",
        "\n",
        "The system's core objective is to monitor and respond to specific objects entering the ROI while ignoring others, ensuring a targeted and efficient defense mechanism that can be adapted to various contexts. It leverages YOLO (You Only Look Once) for object detection and DeepSORT (Simple Online and Realtime Tracking with a Deep Association Metric) for tracking across frames.\n",
        "\n",
        "🚀 𝐊𝐞𝐲 𝐅𝐞𝐚𝐭𝐮𝐫𝐞𝐬:\n",
        "\n",
        "𝐓𝐚𝐫𝐠𝐞𝐭𝐞𝐝 𝐃𝐞𝐭𝐞𝐜𝐭𝐢𝐨𝐧, 𝐃𝐢𝐬𝐜𝐫𝐢𝐦𝐢𝐧𝐚𝐭𝐢𝐨𝐧, 𝐚𝐧𝐝 𝐓𝐫𝐚𝐜𝐤𝐢𝐧𝐠  \n",
        "Detects and tracks specific objects in real time, distinguishing them from other non-relevant objects.  \n",
        "𝐍𝐨𝐧-𝐈𝐧𝐭𝐞𝐫𝐚𝐜𝐭𝐢𝐨𝐧 𝐰𝐢𝐭𝐡 𝐍𝐨𝐧-𝐓𝐚𝐫𝐠𝐞𝐭𝐬  \n",
        "Identifies non-target objects without tracking or interacting with them, allowing resources to focus on the designated threat.  \n",
        "𝐑𝐎𝐈-𝐁𝐚𝐬𝐞𝐝 𝐑𝐞𝐬𝐩𝐨𝐧𝐬𝐞  \n",
        "Triggers specific responses when the target object enters the ROI. For a playful experience, the system “feeds” birds with virtual peanuts in a hostile manner, creating a fun, game-like interaction.\n",
        "\n",
        "📌 𝐏𝐨𝐭𝐞𝐧𝐭𝐢𝐚𝐥 𝐀𝐩𝐩𝐥𝐢𝐜𝐚𝐭𝐢𝐨𝐧𝐬:\n",
        "\n",
        "𝐃𝐫𝐨𝐧𝐞 𝐃𝐞𝐟𝐞𝐧𝐬𝐞 𝐒𝐲𝐬𝐭𝐞𝐦𝐬: Prevent unauthorized drones from entering restricted areas, such as military zones or private property.  \n",
        "𝐈𝐧𝐝𝐮𝐬𝐭𝐫𝐢𝐚𝐥 𝐒𝐢𝐭𝐞 𝐒𝐞𝐜𝐮𝐫𝐢𝐭𝐲: Detect and track specific intrusions near sensitive equipment or infrastructure.  \n",
        "𝐄𝐯𝐞𝐧𝐭 𝐒𝐮𝐫𝐯𝐞𝐢𝐥𝐥𝐚𝐧𝐜𝐞: Monitor large gatherings for unauthorized flying objects like drones.  \n",
        "𝐁𝐨𝐫𝐝𝐞𝐫 𝐏𝐫𝐨𝐭𝐞𝐜𝐭𝐢𝐨𝐧: Track specific aircraft crossing borders in restricted zones.  \n",
        "𝐖𝐢𝐥𝐝𝐥𝐢𝐟𝐞 𝐏𝐫𝐨𝐭𝐞𝐜𝐭𝐢𝐨𝐧: Safeguard sensitive areas from specific animals, e.g., protecting crops from birds or other wildlife.  \n",
        "𝐀𝐢𝐫 𝐓𝐫𝐚𝐟𝐟𝐢𝐜 𝐒𝐚𝐟𝐞𝐭𝐲: Defend airspace from unauthorized drones or birds near airports."
      ],
      "metadata": {
        "id": "4y6fbedDnlPw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ou0uODr-MYi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep_sort_realtime opencv-python-headless\n",
        "!pip install opencv-python\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "l2p3uh1I-N9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from ultralytics import YOLO\n",
        "import random\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Initialize DeepSORT tracker\n",
        "tracker = DeepSort(max_age=5)\n",
        "\n",
        "# Load video\n",
        "video_path = '/content/drive/MyDrive/path_to_seagulls_video/seagulls_video.mp4' # Replace with your path\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get video properties for output\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Set the Region of Interest (ROI)\n",
        "roi_width = 950\n",
        "roi_height = 2 * frame_height // 5\n",
        "roi_top_left = (100, 100)\n",
        "roi_bottom_right = (roi_width, roi_height)\n",
        "\n",
        "line_thickness = 2\n",
        "output_path = '/content/drive/MyDrive/Peanut Feeder for Birds.mp4' # Replace with your path\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Load plane image with alpha channel (transparency)\n",
        "plane_img = cv2.imread('/content/drive/MyDrive/path_to_airplane_picture/airplane_picture.png', cv2.IMREAD_UNCHANGED) # Replace with your path (the picture needs to be in .png format).\n",
        "plane_width = 100\n",
        "plane_height = 50\n",
        "plane_x = 1200  # Starting x position\n",
        "plane_y = 200  # Starting y position\n",
        "\n",
        "# Load helicopter image with alpha channel (transparency)\n",
        "helicopter_img = cv2.imread('/content/drive/MyDrive/path_to_helicopter_picture/helicopter_picture.png', cv2.IMREAD_UNCHANGED) # Replace with your path (the picture needs to be in .png format).\n",
        "helicopter_width = 140\n",
        "helicopter_height = 92\n",
        "helicopter_x = 160  # Starting x position\n",
        "helicopter_y = 450  # Starting y position\n",
        "\n",
        "# Initialize peanut shot state\n",
        "peanut_shot_flash_counter = 0  # Counter for flashing \"Peanut Shot!\" text\n",
        "peanut_flash_duration = 15  # Number of frames for which the text is visible\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run YOLOv8 object detection\n",
        "    results = model(frame)\n",
        "    confidence_threshold = 0.4\n",
        "    detections = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            class_id = int(box.cls[0])\n",
        "            confidence = box.conf[0]\n",
        "            if confidence > confidence_threshold:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                if class_id == 14:  # class_id 14 is for birds\n",
        "                    width = x2 - x1\n",
        "                    height = y2 - y1\n",
        "                    detections.append([[x1, y1, width, height], confidence, class_id])\n",
        "\n",
        "    if detections:\n",
        "        tracks = tracker.update_tracks(detections, frame=frame)\n",
        "        for track in tracks:\n",
        "            bbox = track.to_tlbr()\n",
        "            track_id = track.track_id\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            label = \"Bird\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), line_thickness)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "            if (x1 < roi_bottom_right[0] and x2 > roi_top_left[0] and\n",
        "                y1 < roi_bottom_right[1] and y2 > roi_top_left[1]):\n",
        "                peanut_start = (frame_width // 2, frame_height - 50)\n",
        "                peanut_end = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "                cv2.arrowedLine(frame, peanut_start, peanut_end, (0, 165, 255), 2, tipLength=0.15)\n",
        "\n",
        "                # Flashing effect for \"Peanut Shot!\" text\n",
        "                if peanut_shot_flash_counter == 0:\n",
        "                    cv2.putText(frame, \"Peanut Shot!\", (425, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "                    peanut_shot_flash_counter = peanut_flash_duration\n",
        "                elif peanut_shot_flash_counter > 0:\n",
        "                    peanut_shot_flash_counter -= 1\n",
        "\n",
        "    plane_x -= 2  # Move plane slowly to the left\n",
        "\n",
        "    # Resize plane image to fit within the frame\n",
        "    plane_img_resized = cv2.resize(plane_img, (plane_width, plane_height))\n",
        "\n",
        "    # Ensure it matches the color channels (BGR from RGBA)\n",
        "    if plane_img_resized.shape[2] == 4:  # If it has an alpha channel\n",
        "        # Split the image into BGRA channels (BGR + Alpha)\n",
        "        bgr_plane = plane_img_resized[:, :, :3]\n",
        "        alpha_plane = plane_img_resized[:, :, 3]\n",
        "\n",
        "        # Resize and position the plane image in the frame\n",
        "        x_end = plane_x + plane_width\n",
        "        y_end = plane_y + plane_height\n",
        "\n",
        "        # Create a mask based on the alpha channel\n",
        "        mask = alpha_plane / 255.0\n",
        "        mask_inv = 1.0 - mask\n",
        "\n",
        "        # Blend the frame and plane using the mask\n",
        "        for c in range(0, 3):  # For each channel (BGR)\n",
        "            frame[plane_y:y_end, plane_x:x_end, c] = (frame[plane_y:y_end, plane_x:x_end, c] * mask_inv +\n",
        "                                                      bgr_plane[:, :, c] * mask)\n",
        "\n",
        "    # Slowly move the helicopter upwards and to the right\n",
        "    helicopter_y -= random.choices([0, 1, -1], weights=[3, 3, 1], k=1)[0]\n",
        "    helicopter_x -= random.choices([0, 1, -1], weights=[5, 1, 3], k=1)[0]\n",
        "\n",
        "    # Resize helicopter image to fit within the frame\n",
        "    helicopter_img_resized = cv2.resize(helicopter_img, (helicopter_width, helicopter_height))\n",
        "\n",
        "    # Ensure it matches the color channels (BGR from RGBA)\n",
        "    if helicopter_img_resized.shape[2] == 4:  # If it has an alpha channel\n",
        "        # Split the image into BGRA channels (BGR + Alpha)\n",
        "        bgr_helicopter = helicopter_img_resized[:, :, :3]\n",
        "        alpha_helicopter = helicopter_img_resized[:, :, 3]\n",
        "\n",
        "        # Resize and position the helicopter image in the frame\n",
        "        x_end = helicopter_x + helicopter_width\n",
        "        y_end = helicopter_y + helicopter_height\n",
        "\n",
        "        # Create a mask based on the alpha channel\n",
        "        mask = alpha_helicopter / 255.0\n",
        "        mask_inv = 1.0 - mask\n",
        "\n",
        "        # Blend the frame and helicopter using the mask\n",
        "        for c in range(0, 3):  # For each channel (BGR)\n",
        "            frame[helicopter_y:y_end, helicopter_x:x_end, c] = (frame[helicopter_y:y_end, helicopter_x:x_end, c] * mask_inv +\n",
        "                                                                  bgr_helicopter[:, :, c] * mask)\n",
        "\n",
        "    cv2.rectangle(frame, roi_top_left, roi_bottom_right, (255, 0, 0), line_thickness)\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(f\"Processed video saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "kG9sE1Ix-Q85"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}